# -*- coding: utf-8 -*-
"""AIagentforStockprice.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1X88LfzRw_HiVeUnj0L9awHvTKqke_27f
"""

!pip install streamlit

import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import yfinance as yf
from datetime import datetime, timedelta
from sklearn.preprocessing import MinMaxScaler
from sklearn.ensemble import RandomForestRegressor
from sklearn.linear_model import LinearRegression
import nltk
from textblob import TextBlob
import random
import warnings
warnings.filterwarnings('ignore')

# Download NLTK resources (only needed first time)
try:
    nltk.data.find('vader_lexicon')
except:
    nltk.download('vader_lexicon')

# Set page config
st.set_page_config(
    page_title="Stock Sentiment Analyzer",
    page_icon="üìà",
    layout="wide"
)

# Define the tech companies and their symbols
COMPANIES = {
    "Google (GOOG)": "GOOG",
    "Apple (AAPL)": "AAPL",
    "Amazon (AMZN)": "AMZN",
    "Meta (META)": "META",
    "Netflix (NFLX)": "NFLX",
    "Nvidia (NVDA)": "NVDA",
    "Microsoft (MSFT)": "MSFT",
    "TCS": "TCS"
}

# === STOCK DATA FUNCTIONS ===
def get_stock_data(ticker, start_date, end_date):
    """Fetch historical stock data for a given ticker."""
    try:
        data = yf.download(ticker, start=start_date, end=end_date)

        if data.empty:
            return pd.DataFrame()

        # Format the data
        data = data.reset_index()
        data['Date'] = pd.to_datetime(data['Date'])
        data.set_index('Date', inplace=True)

        # Calculate technical indicators
        data = calculate_technical_indicators(data)

        return data
    except Exception as e:
        st.error(f"Error fetching stock data: {str(e)}")
        return pd.DataFrame()

def calculate_technical_indicators(data):
    """Calculate various technical indicators for stock analysis."""
    # Moving Averages
    data['SMA_20'] = data['Close'].rolling(window=20, min_periods=1).mean()
    data['SMA_50'] = data['Close'].rolling(window=50, min_periods=1).mean()

    # RSI
    delta = data['Close'].diff()
    gain = delta.where(delta > 0, 0).rolling(window=14).mean()
    loss = -delta.where(delta < 0, 0).rolling(window=14).mean()
    rs = gain / loss
    data['RSI'] = 100 - (100 / (1 + rs))

    # MACD
    data['EMA_12'] = data['Close'].ewm(span=12, adjust=False).mean()
    data['EMA_26'] = data['Close'].ewm(span=26, adjust=False).mean()
    data['MACD'] = data['EMA_12'] - data['EMA_26']
    data['MACD_signal'] = data['MACD'].ewm(span=9, adjust=False).mean()

    return data

# === TWITTER/SENTIMENT FUNCTIONS ===
def clean_tweet(tweet_text):
    """Clean and preprocess tweet text."""
    # In a production environment, this would do more complex text cleaning
    return tweet_text.lower()

def get_sentiment_score(text):
    """Calculate sentiment score using TextBlob."""
    analysis = TextBlob(text)
    return analysis.sentiment.polarity

def simulate_tweets(company_name, count=100):
    """Generate simulated tweets for demonstration purposes."""
    sentiments = ["positive", "negative", "neutral"]
    weights = [0.4, 0.3, 0.3]  # Slightly more positive than negative

    # Template phrases for each sentiment
    positive_phrases = [
        f"Just bought {company_name} stock! Excited about their future!",
        f"{company_name} is crushing it right now, amazing performance",
        f"Really impressed with {company_name}'s latest product release",
        f"{company_name} earnings beat expectations! Going higher!",
        f"The management at {company_name} is fantastic, very bullish"
    ]

    negative_phrases = [
        f"Not happy with my {company_name} investment, thinking of selling",
        f"{company_name}'s customer service is terrible, avoid this stock",
        f"{company_name} missed earnings again, disappointing",
        f"The new leadership at {company_name} seems lost",
        f"Competition is eating {company_name}'s market share, worried"
    ]

    neutral_phrases = [
        f"Wondering if {company_name} will announce anything new soon",
        f"Holding my {company_name} shares for now, waiting for news",
        f"Anyone have thoughts on {company_name} stock?",
        f"Watching {company_name} stock price today, interesting movement",
        f"Just read an article about {company_name}, not sure what to think"
    ]

    tweets = []
    now = datetime.now()

    for i in range(count):
        sentiment_type = random.choices(sentiments, weights=weights)[0]

        if sentiment_type == "positive":
            text = random.choice(positive_phrases)
        elif sentiment_type == "negative":
            text = random.choice(negative_phrases)
        else:
            text = random.choice(neutral_phrases)

        # Add some randomization
        if random.random() > 0.7:
            text += " " + random.choice([
                "#stocks", "#investing", "#trading",
                "#bullish", "#bearish", "#marketwatch"
            ])

        # Create timestamp within the past 7 days
        random_days = random.uniform(0, 7)
        timestamp = now - timedelta(days=random_days)

        tweets.append({
            "text": text,
            "timestamp": timestamp
        })

    return tweets

def fetch_tweets(company_name, count=100, days_back=7):
    """Fetch tweets related to a company. In this demo version, we simulate tweets."""
    # Display a clear message that data is simulated
    st.info("‚ö†Ô∏è Using simulated tweets for demonstration. Connect a real Twitter API for production use.")

    # Generate simulated tweets
    tweets = simulate_tweets(company_name, count)

    return tweets

def analyze_sentiment(tweets):
    """Analyze sentiment of a list of tweets."""
    sentiment_results = []

    for tweet in tweets:
        cleaned_text = clean_tweet(tweet["text"])
        sentiment_score = get_sentiment_score(cleaned_text)

        sentiment_results.append({
            "text": tweet["text"],
            "timestamp": tweet["timestamp"],
            "sentiment_score": sentiment_score
        })

    return pd.DataFrame(sentiment_results)

# === PREDICTION MODEL FUNCTIONS ===
def prepare_data_for_model(stock_data, sentiment_data=None, days_to_predict=5, look_back=10):
    """Prepare data for the prediction model."""
    # Create a copy to avoid modifying the original
    data = stock_data.copy()

    # Add basic features
    data['SMA_5'] = data['Close'].rolling(window=5, min_periods=1).mean()
    data['SMA_20'] = data['Close'].rolling(window=20, min_periods=1).mean()
    data['day_of_week'] = data.index.dayofweek
    data['price_momentum'] = data['Close'].pct_change(5)
    data['volume_change'] = data['Volume'].pct_change()

    # Add sentiment data if available
    if sentiment_data is not None and not sentiment_data.empty:
        # Resample sentiment to match stock data dates
        sentiment_resampled = sentiment_data.resample('D').mean().fillna(0)
        data = data.join(sentiment_resampled, how='left')
        data['sentiment_score'] = data['sentiment_score'].fillna(0)
        features = ['Close', 'Volume', 'SMA_5', 'SMA_20', 'day_of_week', 'price_momentum', 'volume_change', 'sentiment_score']
    else:
        # Use only price-based features if sentiment is not available
        data['sentiment_score'] = 0  # Add dummy sentiment
        features = ['Close', 'Volume', 'SMA_5', 'SMA_20', 'day_of_week', 'price_momentum', 'volume_change']

    # Fill NaN values
    data = data.ffill().bfill().fillna(0)

    # Create sequences
    X, y = [], []
    for i in range(look_back, len(data) - days_to_predict):
        X.append(data[features].iloc[i-look_back:i].values.flatten())
        y.append(data['Close'].iloc[i+days_to_predict])

    # Convert to numpy arrays
    X = np.array(X)
    y = np.array(y)

    # Normalize features
    scaler = MinMaxScaler()
    X_scaled = scaler.fit_transform(X)

    # Prepare recent data for prediction
    most_recent_x = data[features].iloc[-look_back:].values.flatten().reshape(1, -1)
    most_recent_x_scaled = scaler.transform(most_recent_x)

    return X_scaled, y, scaler, most_recent_x_scaled

def train_prediction_model(stock_data, sentiment_data=None, look_back=10):
    """Train a model to predict stock prices."""
    # Prepare data
    X_scaled, y, scaler, most_recent_x_scaled = prepare_data_for_model(stock_data, sentiment_data, look_back=look_back)

    # Choose model based on data size
    if len(X_scaled) < 20:
        model = LinearRegression()
    else:
        model = RandomForestRegressor(n_estimators=100, random_state=42)

    # Train the model
    if len(X_scaled) > 0 and len(y) > 0:
        model.fit(X_scaled, y)
        return model, scaler, most_recent_x_scaled
    else:
        st.error("Not enough data to train the model")
        return None, None, None

def predict_stock_price(model, scaler, recent_data_scaled, days_ahead=5):
    """Predict stock prices for days ahead."""
    predictions = []

    for _ in range(days_ahead):
        # Predict the next day's price
        prediction = model.predict(recent_data_scaled)[0]
        predictions.append(prediction)

    return predictions

# === UTILITY FUNCTIONS ===
def format_large_number(num):
    """Format large numbers in a readable way (K, M, B)."""
    if num >= 1_000_000_000:
        return f"{num / 1_000_000_000:.2f}B"
    elif num >= 1_000_000:
        return f"{num / 1_000_000:.2f}M"
    elif num >= 1_000:
        return f"{num / 1_000:.2f}K"
    else:
        return f"{num:.2f}"

def calculate_correlation(sentiment_data, stock_data):
    """Calculate correlation between sentiment and stock price."""
    try:
        # Align dates
        common_dates = sentiment_data.index.intersection(stock_data.index)

        if len(common_dates) < 2:
            return 0

        # Calculate correlation
        sentiment_aligned = sentiment_data.loc[common_dates]
        stock_aligned = stock_data.loc[common_dates]

        correlation = sentiment_aligned['sentiment_score'].corr(stock_aligned)
        return correlation
    except Exception as e:
        st.error(f"Error calculating correlation: {str(e)}")
        return 0

# Initialize session state
if 'current_company' not in st.session_state:
    st.session_state.current_company = "Google (GOOG)"
if 'prediction_days' not in st.session_state:
    st.session_state.prediction_days = 5
if 'time_period' not in st.session_state:
    st.session_state.time_period = 30

# App title and description
st.title("Stock Sentiment Analyzer")
st.markdown("### AI-powered tool for stock price prediction based on social media sentiment")

# Sidebar
with st.sidebar:
    st.header("Configuration")

    # Company selection
    selected_company = st.selectbox(
        "Select a company",
        list(COMPANIES.keys()),
        index=list(COMPANIES.keys()).index(st.session_state.current_company)
    )

    # Time period selection
    time_period = st.slider(
        "Historical Data (days)",
        min_value=7,
        max_value=90,
        value=st.session_state.time_period,
        step=1
    )

    # Prediction days
    prediction_days = st.slider(
        "Prediction Days",
        min_value=1,
        max_value=10,
        value=st.session_state.prediction_days,
        step=1
    )

    # Update button
    if st.button("Update Analysis"):
        st.session_state.current_company = selected_company
        st.session_state.time_period = time_period
        st.session_state.prediction_days = prediction_days
        st.rerun()

    st.markdown("---")
    st.markdown("#### About")
    st.markdown(
        "This application analyzes social media sentiment to predict stock prices "
        "for major tech companies. It uses Twitter/X data to gauge market sentiment "
        "and correlates it with stock price movements."
    )

# Main content
company_name = st.session_state.current_company
company_symbol = COMPANIES[company_name]
time_period = st.session_state.time_period
prediction_days = st.session_state.prediction_days

# Create tabs
tab1, tab2, tab3 = st.tabs(["Stock Analysis", "Sentiment Analysis", "Predictions"])

with tab1:
    st.header(f"{company_name} Stock Analysis")

    # Get stock data
    with st.spinner("Fetching stock data..."):
        try:
            end_date = datetime.now()
            start_date = end_date - timedelta(days=time_period)
            stock_data = get_stock_data(company_symbol, start_date, end_date)

            if stock_data.empty:
                st.error(f"No stock data available for {company_name}")
            else:
                # Display basic metrics
                col1, col2, col3, col4 = st.columns(4)

                current_price = stock_data['Close'].iloc[-1]
                previous_price = stock_data['Close'].iloc[-2]
                price_change = current_price - previous_price
                price_change_pct = (price_change / previous_price) * 100

                col1.metric(
                    "Current Price",
                    f"${current_price:.2f}",
                    f"{price_change:.2f} ({price_change_pct:.2f}%)"
                )

                col2.metric(
                    "Trading Volume",
                    format_large_number(stock_data['Volume'].iloc[-1])
                )

                highest_price = stock_data['High'].max()
                col3.metric("Highest Price", f"${highest_price:.2f}")

                lowest_price = stock_data['Low'].min()
                col4.metric("Lowest Price", f"${lowest_price:.2f}")

                # Plot stock price
                fig = go.Figure()
                fig.add_trace(
                    go.Scatter(
                        x=stock_data.index,
                        y=stock_data['Close'],
                        mode='lines',
                        name='Close Price',
                        line=dict(color='rgba(0, 128, 255, 1)')
                    )
                )

                fig.update_layout(
                    title=f"{company_name} Stock Price",
                    xaxis_title="Date",
                    yaxis_title="Price (USD)",
                    template="plotly_white",
                    height=500
                )

                st.plotly_chart(fig, use_container_width=True)

                # Trading volume chart
                volume_fig = px.bar(
                    stock_data,
                    x=stock_data.index,
                    y='Volume',
                    title=f"{company_name} Trading Volume"
                )

                volume_fig.update_layout(
                    xaxis_title="Date",
                    yaxis_title="Volume",
                    template="plotly_white",
                    height=400
                )

                st.plotly_chart(volume_fig, use_container_width=True)

        except Exception as e:
            st.error(f"Error fetching stock data: {str(e)}")

with tab2:
    st.header(f"{company_name} Sentiment Analysis")

    with st.spinner("Fetching tweets and analyzing sentiment..."):
        try:
            # Fetch tweets about the company
            company_short_name = company_name.split('(')[0].strip()
            tweets = fetch_tweets(company_short_name, count=100)

            if not tweets:
                st.warning(f"No tweets found for {company_short_name}")
            else:
                # Analyze sentiment
                sentiment_df = analyze_sentiment(tweets)

                # Display sentiment metrics
                col1, col2, col3 = st.columns(3)

                avg_sentiment = sentiment_df['sentiment_score'].mean()
                sentiment_status = "Positive" if avg_sentiment > 0.05 else "Negative" if avg_sentiment < -0.05 else "Neutral"
                sentiment_color = "green" if sentiment_status == "Positive" else "red" if sentiment_status == "Negative" else "orange"

                col1.metric(
                    "Average Sentiment",
                    f"{avg_sentiment:.2f}",
                    sentiment_status
                )

                positive_pct = (sentiment_df['sentiment_score'] > 0).mean() * 100
                col2.metric("Positive Tweets", f"{positive_pct:.1f}%")

                negative_pct = (sentiment_df['sentiment_score'] < 0).mean() * 100
                col3.metric("Negative Tweets", f"{negative_pct:.1f}%")

                # Sentiment distribution chart
                sentiment_df['sentiment_category'] = pd.cut(
                    sentiment_df['sentiment_score'],
                    bins=[-1, -0.5, -0.05, 0.05, 0.5, 1],
                    labels=['Very Negative', 'Negative', 'Neutral', 'Positive', 'Very Positive']
                )

                sentiment_counts = sentiment_df['sentiment_category'].value_counts().reset_index()
                sentiment_counts.columns = ['Sentiment', 'Count']

                sentiment_fig = px.bar(
                    sentiment_counts,
                    x='Sentiment',
                    y='Count',
                    color='Sentiment',
                    title='Sentiment Distribution',
                    color_discrete_map={
                        'Very Negative': 'darkred',
                        'Negative': 'red',
                        'Neutral': 'gray',
                        'Positive': 'green',
                        'Very Positive': 'darkgreen'
                    }
                )

                sentiment_fig.update_layout(
                    xaxis_title="Sentiment Category",
                    yaxis_title="Number of Tweets",
                    template="plotly_white",
                    height=400
                )

                st.plotly_chart(sentiment_fig, use_container_width=True)

                # Calculate correlation with stock price
                if not stock_data.empty and len(stock_data) > 5:
                    # Group sentiment by day for correlation analysis
                    sentiment_df['date'] = pd.to_datetime(sentiment_df['timestamp']).dt.date
                    daily_sentiment = sentiment_df.groupby('date')['sentiment_score'].mean().reset_index()
                    daily_sentiment['date'] = pd.to_datetime(daily_sentiment['date'])
                    daily_sentiment.set_index('date', inplace=True)

                    # Prepare stock data for correlation
                    stock_price_daily = stock_data['Close'].resample('D').last().dropna()

                    # Align dates and calculate correlation
                    correlation = calculate_correlation(daily_sentiment, stock_price_daily)

                    st.subheader("Sentiment vs. Stock Price Correlation")
                    st.write(f"Correlation coefficient: {correlation:.2f}")

                    # Correlation interpretation
                    if abs(correlation) < 0.2:
                        st.write("There is very weak or no correlation between social media sentiment and stock price.")
                    elif abs(correlation) < 0.4:
                        st.write("There is a weak correlation between social media sentiment and stock price.")
                    elif abs(correlation) < 0.6:
                        st.write("There is a moderate correlation between social media sentiment and stock price.")
                    elif abs(correlation) < 0.8:
                        st.write("There is a strong correlation between social media sentiment and stock price.")
                    else:
                        st.write("There is a very strong correlation between social media sentiment and stock price.")

                # Show recent tweets and their sentiment
                st.subheader("Recent Tweets and Sentiment")

                display_tweets = sentiment_df.sort_values('timestamp', ascending=False).head(10)
                for i, row in display_tweets.iterrows():
                    sentiment_value = row['sentiment_score']
                    sentiment_color = "green" if sentiment_value > 0.05 else "red" if sentiment_value < -0.05 else "orange"

                    st.markdown(
                        f"<div style='border-left: 4px solid {sentiment_color}; padding-left: 10px; margin-bottom: 15px;'>"
                        f"<p>{row['text']}</p>"
                        f"<p style='color: {sentiment_color}; margin-bottom: 0;'>Sentiment: {sentiment_value:.2f}</p>"
                        f"<small>{row['timestamp']}</small>"
                        f"</div>",
                        unsafe_allow_html=True
                    )

        except Exception as e:
            st.error(f"Error analyzing sentiment: {str(e)}")

with tab3:
    st.header(f"{company_name} Stock Price Predictions")

    with st.spinner("Generating predictions..."):
        try:
            # Get stock data for model training
            end_date = datetime.now()
            training_start_date = end_date - timedelta(days=max(90, time_period*2))  # Use more data for training
            stock_data_extended = get_stock_data(company_symbol, training_start_date, end_date)

            if stock_data_extended.empty:
                st.error(f"No stock data available for {company_name} to make predictions")
            else:
                # Fetch tweets for sentiment analysis
                company_short_name = company_name.split('(')[0].strip()
                tweets = fetch_tweets(company_short_name, count=200)

                if not tweets:
                    st.warning(f"No tweets found for {company_short_name}. Predictions will be based only on historical data.")
                    sentiment_data = None
                else:
                    # Analyze sentiment and prepare for model
                    sentiment_df = analyze_sentiment(tweets)
                    sentiment_df['date'] = pd.to_datetime(sentiment_df['timestamp']).dt.date
                    daily_sentiment = sentiment_df.groupby('date')['sentiment_score'].mean().reset_index()
                    daily_sentiment['date'] = pd.to_datetime(daily_sentiment['date'])
                    daily_sentiment.set_index('date', inplace=True)
                    sentiment_data = daily_sentiment

                # Train model and make predictions
                model, scaler, X_recent = train_prediction_model(stock_data_extended, sentiment_data)

                if model is not None:
                    # Make predictions for the next days
                    prediction_dates = [end_date + timedelta(days=i+1) for i in range(prediction_days)]
                    predicted_prices = predict_stock_price(model, scaler, X_recent, prediction_days)

                    # Display prediction results
                    last_actual_price = stock_data_extended['Close'].iloc[-1]

                    col1, col2 = st.columns(2)

                    with col1:
                        st.metric(
                            "Current Price",
                            f"${last_actual_price:.2f}"
                        )

                    with col2:
                        price_change = predicted_prices[-1] - last_actual_price
                        price_change_pct = (price_change / last_actual_price) * 100
                        st.metric(
                            f"Predicted Price ({prediction_days} days)",
                            f"${predicted_prices[-1]:.2f}",
                            f"{price_change:.2f} ({price_change_pct:.2f}%)"
                        )

                    # Create a table with daily predictions
                    prediction_df = pd.DataFrame({
                        'Date': prediction_dates,
                        'Predicted Price': predicted_prices
                    })

                    st.subheader("Daily Price Predictions")
                    st.dataframe(
                        prediction_df.style.format({'Predicted Price': '${:.2f}'}),
                        use_container_width=True
                    )

                    # Create visualization with historical data and predictions
                    fig = go.Figure()

                    # Add historical data
                    fig.add_trace(
                        go.Scatter(
                            x=stock_data_extended.index[-30:],  # Last 30 days
                            y=stock_data_extended['Close'].iloc[-30:],
                            mode='lines',
                            name='Historical Price',
                            line=dict(color='blue')
                        )
                    )

                    # Add predictions
                    fig.add_trace(
                        go.Scatter(
                            x=prediction_df['Date'],
                            y=prediction_df['Predicted Price'],
                            mode='lines+markers',
                            name='Predicted Price',
                            line=dict(color='red', dash='dash'),
                            marker=dict(size=8)
                        )
                    )

                    fig.update_layout(
                        title=f"{company_name} Stock Price Prediction",
                        xaxis_title="Date",
                        yaxis_title="Price (USD)",
                        template="plotly_white",
                        height=500
                    )

                    st.plotly_chart(fig, use_container_width=True)

        except Exception as e:
            st.error(f"Error generating predictions: {str(e)}")